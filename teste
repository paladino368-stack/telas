import pandas as pd
import os
import sys
from difflib import SequenceMatcher
from typing import Any, List, Tuple, Dict
from datetime import datetime

# ==============================================================================
# BLOCO ORIGINAL (OTIMIZADO, MANTENDO A L√ìGICA)
# ==============================================================================

def _carregar_dataframe(caminho_arquivo: str, sheet_name: Any = 0) -> pd.DataFrame:
    """
    Carrega dinamicamente um arquivo (CSV ou Excel) em um DataFrame do Pandas.
    Para Excel, permite a especifica√ß√£o da planilha.
    """
    extensao = os.path.splitext(caminho_arquivo)[1].lower()
    print(f"\nüîÑ Carregando arquivo: '{os.path.basename(caminho_arquivo)}' (extens√£o: {extensao})")

    try:
        if extensao == '.csv':
            return pd.read_csv(caminho_arquivo, low_memory=False, dtype=str)
        elif extensao == '.xlsx':
            return pd.read_excel(caminho_arquivo, sheet_name=sheet_name, dtype=str)
        else:
            raise ValueError(f"Extens√£o '{extensao}' n√£o suportada. Use .csv ou .xlsx")
    except FileNotFoundError:
        raise FileNotFoundError(f"ERRO: O arquivo '{caminho_arquivo}' n√£o foi encontrado.")
    except Exception as e:
        raise Exception(f"ERRO ao ler o arquivo '{caminho_arquivo}': {e}")

# NOVA FUN√á√ÉO AUXILIAR PARA NORMALIZA√á√ÉO DE DATAS
def _normalizar_colunas_de_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Identifica colunas que provavelmente cont√™m datas pelo nome e normaliza
    seus formatos para 'YYYY-MM-DD' de forma otimizada.
    """
    df_norm = df.copy()
    # Palavras-chave para identificar colunas de data. Adicione outras se necess√°rio.
    PALAVRAS_CHAVE_DATA = ['data', 'date', 'dt_', '_dt', 'timestamp']
    
    for col in df_norm.columns:
        # Verifica se alguma palavra-chave est√° no nome da coluna (ignorando mai√∫sculas/min√∫sculas)
        if any(palavra in col.lower() for palavra in PALAVRAS_CHAVE_DATA):
            try:
                # Tenta converter a coluna inteira para datetime.
                # errors='coerce' transforma falhas em NaT (Not a Time), n√£o quebra a execu√ß√£o.
                coluna_convertida = pd.to_datetime(df_norm[col], errors='coerce')
                
                # Cria uma m√°scara para saber quais valores foram convertidos com sucesso
                mascara_datas_validas = coluna_convertida.notna()
                
                # Aplica a formata√ß√£o padr√£o 'YYYY-MM-DD' apenas nas datas v√°lidas
                # e atribui de volta √† coluna original do DataFrame copiado.
                df_norm.loc[mascara_datas_validas, col] = coluna_convertida[mascara_datas_validas].dt.strftime('%Y-%m-%d')
            except Exception:
                # Se ocorrer um erro inesperado na convers√£o, apenas segue em frente,
                # mantendo a coluna original para compara√ß√£o.
                pass
    return df_norm

def comparador_avancado_arquivos(
    caminho_arquivo1: str,
    caminho_arquivo2: str,
    sheet1: Any = 0,
    sheet2: Any = 0,
    peso_estrutura: float = 0.3,
    peso_colunas: float = 0.4,
    peso_conteudo: float = 0.3,
    limite_linhas_conteudo: int = 10000
) -> float:
    """
    Compara de forma avan√ßada e otimizada a similaridade entre dois arquivos.
    A an√°lise de conte√∫do √© feita em uma amostra de linhas para performance.
    """
    print("======================================================")
    print(f"üöÄ INICIANDO COMPARA√á√ÉO AVAN√áADA ENTRE '{os.path.basename(caminho_arquivo1)}' E '{os.path.basename(caminho_arquivo2)}' üöÄ")
    print("======================================================")
    
    try:
        df1 = _carregar_dataframe(caminho_arquivo1, sheet_name=sheet1)
        df2 = _carregar_dataframe(caminho_arquivo2, sheet_name=sheet2)
    except (ValueError, FileNotFoundError, Exception) as e:
        print(f"\n‚ùå A an√°lise foi interrompida devido a um erro de carregamento: {e}")
        return 0.0

    # --- 1. AN√ÅLISE ESTRUTURAL (DIMENS√ïES) ---
    print("\n---------- ETAPA 1: AN√ÅLISE ESTRUTURAL (DIMENS√ïES) ----------")
    shape1 = df1.shape
    shape2 = df2.shape
    print(f"Dimens√µes Arquivo 1: {shape1[0]} linhas, {shape1[1]} colunas.")
    print(f"Dimens√µes Arquivo 2: {shape2[0]} linhas, {shape2[1]} colunas.")
    
    sim_linhas = min(shape1[0], shape2[0]) / max(shape1[0], shape2[0]) if max(shape1[0], shape2[0]) > 0 else 1.0
    sim_colunas_total = min(shape1[1], shape2[1]) / max(shape1[1], shape2[1]) if max(shape1[1], shape2[1]) > 0 else 1.0
    score_estrutura = (sim_linhas + sim_colunas_total) / 2
    print(f"üìä Pontua√ß√£o de Similaridade Estrutural: {score_estrutura:.2%}")

    # --- 2. AN√ÅLISE DOS NOMES DAS COLUNAS ---
    print("\n---------- ETAPA 2: AN√ÅLISE DOS NOMES DAS COLUNAS ----------")
    cols1 = set(df1.columns)
    cols2 = set(df2.columns)
    
    if cols1 == cols2:
        print("‚úÖ Sucesso! Os nomes das colunas s√£o id√™nticos em ambos os arquivos.")
        score_colunas = 1.0
    else:
        print("‚ö†Ô∏è Aten√ß√£o! Os nomes das colunas s√£o diferentes.")
        intersecao = len(cols1.intersection(cols2))
        uniao = len(cols1.union(cols2))
        score_colunas = intersecao / uniao if uniao > 0 else 0.0
        print(f"   Colunas apenas no Arquivo 1: {sorted(list(cols1 - cols2))}")
        print(f"   Colunas apenas no Arquivo 2: {sorted(list(cols2 - cols1))}")
    
    print(f"üìä Pontua√ß√£o de Similaridade de Colunas: {score_colunas:.2%}")

    # --- 3. AN√ÅLISE DE CONTE√öDO (OTIMIZADA) ---
    print("\n---------- ETAPA 3: AN√ÅLISE DE CONTE√öDO (C√âLULA A C√âLULA) ----------")
    colunas_comuns = sorted(list(cols1.intersection(cols2)))
    score_conteudo = 0.0

    if not colunas_comuns:
        print(" Sem colunas em comum, a compara√ß√£o de conte√∫do n√£o √© poss√≠vel.")
    else:
        df1_comp = df1[colunas_comuns]
        df2_comp = df2[colunas_comuns]
        
        linhas_para_comparar = min(len(df1_comp), len(df2_comp))

        if limite_linhas_conteudo and linhas_para_comparar > limite_linhas_conteudo:
            print(f"‚ö†Ô∏è Para otimiza√ß√£o de performance, o conte√∫do ser√° analisado com base nas primeiras {limite_linhas_conteudo} linhas.")
            linhas_para_comparar = limite_linhas_conteudo
            df1_comp = df1_comp.head(linhas_para_comparar)
            df2_comp = df2_comp.head(linhas_para_comparar)
        
        # ETAPA ADICIONADA: Normaliza√ß√£o de datas antes da compara√ß√£o.
        print("‚ú® Normalizando formatos de data para uma compara√ß√£o justa...")
        df1_comp = _normalizar_colunas_de_data(df1_comp)
        df2_comp = _normalizar_colunas_de_data(df2_comp)

        print(f"Comparando o conte√∫do de {linhas_para_comparar} linhas nas {len(colunas_comuns)} colunas em comum...")

        if df1_comp.equals(df2_comp):
            print("‚ö°Ô∏è Verifica√ß√£o r√°pida: O conte√∫do da amostra analisada √© 100% id√™ntico.")
            score_conteudo = 1.0
        else:
            scores_celulas = []
            if linhas_para_comparar > 0:
                for i in range(linhas_para_comparar):
                    percentual = (i + 1) / linhas_para_comparar
                    barra_progresso = '‚ñà' * int(percentual * 20)
                    sys.stdout.terminal.write(f"  Analisando conte√∫do: [{barra_progresso:<20}] {percentual:.1%} - linha {i+1}/{linhas_para_comparar}\r")
                    
                    for col in colunas_comuns:
                        val1 = df1_comp.at[i, col]
                        val2 = df2_comp.at[i, col]
                        s_val1 = str(val1) if pd.notna(val1) else ""
                        s_val2 = str(val2) if pd.notna(val2) else ""
                        
                        score_celula = SequenceMatcher(None, s_val1, s_val2).ratio()
                        scores_celulas.append(score_celula)
                
                sys.stdout.terminal.write("\n")

                if scores_celulas:
                    score_conteudo = sum(scores_celulas) / len(scores_celulas)

    print(f"üìù Pontua√ß√£o de Similaridade de Conte√∫do: {score_conteudo:.2%}")

    # --- 4. C√ÅLCULO FINAL PONDERADO ---
    print("\n---------- ETAPA 4: C√ÅLCULO FINAL PONDERADO ----------")
    print(f"Pesos aplicados -> Estrutura: {peso_estrutura:.0%}, Nomes Colunas: {peso_colunas:.0%}, Conte√∫do: {peso_conteudo:.0%}")
    
    similaridade_final = (score_estrutura * peso_estrutura) + \
                         (score_colunas * peso_colunas) + \
                         (score_conteudo * peso_conteudo)
    
    print("\n======================================================")
    print(f"üèÜ SIMILARIDADE FINAL CALCULADA: {similaridade_final:.2%}")
    print("======================================================")
    
    return similaridade_final

# ==============================================================================
# BLOCO NOVO: ORQUESTRA√á√ÉO, PAREAMENTO E LOGGING
# ==============================================================================

class Logger(object):
    """
    Classe para redirecionar a sa√≠da (stdout) para um arquivo de log e para o terminal.
    """
    def __init__(self, nome_arquivo="log_comparacao.txt"):
        self.terminal = sys.stdout
        self.log = open(nome_arquivo, "w", encoding='utf-8')

    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)

    def flush(self):
        self.terminal.flush()
        self.log.flush()

# --- FUN√á√ïES PARA O CEN√ÅRIO 1 (SIMILARIDADE DE ESTRUTURA) ---

def _analisar_metadados_diretorio(caminho_dir: str) -> List[Dict[str, Any]]:
    """
    L√™ um diret√≥rio e extrai metadados (caminho, forma, colunas) de cada arquivo.
    """
    metadados = []
    print(f"\nüîé Analisando metadados do diret√≥rio: '{caminho_dir}'")
    for nome_arquivo in os.listdir(caminho_dir):
        caminho_completo = os.path.join(caminho_dir, nome_arquivo)
        if os.path.isfile(caminho_completo) and (nome_arquivo.endswith('.csv') or nome_arquivo.endswith('.xlsx')):
            try:
                df_header_only = _carregar_dataframe_silencioso(caminho_completo, ler_apenas_cabecalho=True)
                df_full = _carregar_dataframe_silencioso(caminho_completo)
                metadados.append({
                    "caminho": caminho_completo,
                    "shape": df_full.shape,
                    "colunas": set(df_header_only.columns)
                })
                print(f"  - Metadados de '{nome_arquivo}' extra√≠dos com sucesso.")
            except Exception as e:
                print(f"  - ‚ùå Falha ao ler metadados de '{nome_arquivo}': {e}")
    return metadados

def _carregar_dataframe_silencioso(caminho_arquivo: str, ler_apenas_cabecalho: bool = False) -> pd.DataFrame:
    """Vers√£o simplificada para carregar DF sem imprimir na tela, com op√ß√£o de ler apenas o cabe√ßalho."""
    extensao = os.path.splitext(caminho_arquivo)[1].lower()
    linhas_para_ler = 1 if ler_apenas_cabecalho else None
    
    if extensao == '.csv':
        return pd.read_csv(caminho_arquivo, low_memory=False, nrows=linhas_para_ler, dtype=str)
    elif extensao == '.xlsx':
        return pd.read_excel(caminho_arquivo, nrows=linhas_para_ler, dtype=str)
    raise ValueError("Extens√£o n√£o suportada.")

def encontrar_pares_de_arquivos_por_similaridade(
    meta_dir_a: List[Dict[str, Any]],
    meta_dir_b: List[Dict[str, Any]],
    limiar_similaridade_previa: float = 0.75
) -> Tuple[List[Tuple[str, str]], List[str], List[str]]:
    """
    Encontra os melhores pares com base na similaridade de estrutura e nomes de colunas.
    """
    print("\nü§ù Iniciando o processo de pareamento por SIMILARIDADE DE ESTRUTURA...")
    
    pares_encontrados = []
    arquivos_b_disponiveis = meta_dir_b[:]
    arquivos_a_pareados = set()

    for meta_a in meta_dir_a:
        melhor_par = None
        maior_score = -1

        for meta_b in arquivos_b_disponiveis:
            intersecao = len(meta_a["colunas"].intersection(meta_b["colunas"]))
            uniao = len(meta_a["colunas"].union(meta_b["colunas"]))
            score_colunas = intersecao / uniao if uniao > 0 else 0.0

            shape_a = meta_a["shape"]
            shape_b = meta_b["shape"]
            sim_colunas_total = min(shape_a[1], shape_b[1]) / max(shape_a[1], shape_b[1]) if max(shape_a[1], shape_b[1]) > 0 else 1.0
            
            score_combinado = (score_colunas * 0.7) + (sim_colunas_total * 0.3)

            if score_combinado > maior_score:
                maior_score = score_combinado
                melhor_par = meta_b

        if melhor_par and maior_score >= limiar_similaridade_previa:
            pares_encontrados.append((meta_a["caminho"], melhor_par["caminho"]))
            arquivos_a_pareados.add(meta_a["caminho"])
            arquivos_b_disponiveis.remove(melhor_par)
            print(f"  - Par encontrado: '{os.path.basename(meta_a['caminho'])}' <=> '{os.path.basename(melhor_par['caminho'])}' (Score pr√©vio: {maior_score:.2%})")

    nao_pareados_a = [meta["caminho"] for meta in meta_dir_a if meta["caminho"] not in arquivos_a_pareados]
    nao_pareados_b = [meta["caminho"] for meta in arquivos_b_disponiveis]

    return pares_encontrados, nao_pareados_a, nao_pareados_b

def processar_comparacao_cenario_padrao(dir_a: str, dir_b: str, limite_linhas: int):
    """
    Orquestrador para o CEN√ÅRIO PADR√ÉO: compara arquivos baseados em similaridade de estrutura.
    """
    metadados_a = _analisar_metadados_diretorio(dir_a)
    metadados_b = _analisar_metadados_diretorio(dir_b)

    pares, nao_pareados_a, nao_pareados_b = encontrar_pares_de_arquivos_por_similaridade(metadados_a, metadados_b)

    _executar_e_resumir_comparacoes(pares, nao_pareados_a, nao_pareados_b, limite_linhas)

# --- FUN√á√ïES PARA O CEN√ÅRIO 2 (PASTA COMO CHAVE) ---

def encontrar_pares_de_arquivos_por_chave_de_pasta(dir_a: str, dir_b: str) -> Tuple[List[Tuple[str, str]], List[str], List[str]]:
    """
    Encontra pares com base na regra: nome da pasta em A == nome do arquivo em B.
    """
    print("\nü§ù Iniciando o processo de pareamento por CHAVE DE PASTA/ARQUIVO...")
    
    mapa_a = {}
    nao_mapeados_a = []
    for nome_pasta in os.listdir(dir_a):
        caminho_pasta = os.path.join(dir_a, nome_pasta)
        if os.path.isdir(caminho_pasta):
            arquivos_na_pasta = [f for f in os.listdir(caminho_pasta) if f.endswith(('.csv', '.xlsx'))]
            if arquivos_na_pasta:
                mapa_a[nome_pasta] = os.path.join(caminho_pasta, arquivos_na_pasta[0])
            else:
                nao_mapeados_a.append(caminho_pasta)

    mapa_b = {}
    for nome_arquivo in os.listdir(dir_b):
        caminho_arquivo = os.path.join(dir_b, nome_arquivo)
        if os.path.isfile(caminho_arquivo) and (nome_arquivo.endswith('.csv') or nome_arquivo.endswith('.xlsx')):
            chave = os.path.splitext(nome_arquivo)[0]
            mapa_b[chave] = caminho_arquivo

    pares_encontrados = []
    chaves_b_pareadas = set()
    for chave_a, caminho_a in mapa_a.items():
        if chave_a in mapa_b:
            caminho_b = mapa_b[chave_a]
            pares_encontrados.append((caminho_a, caminho_b))
            chaves_b_pareadas.add(chave_a)
            print(f"  - Par encontrado: '{os.path.basename(os.path.dirname(caminho_a))}' <=> '{os.path.basename(caminho_b)}'")
    
    nao_pareados_a = [caminho for chave, caminho in mapa_a.items() if chave not in mapa_b]
    nao_pareados_b = [caminho for chave, caminho in mapa_b.items() if chave not in chaves_b_pareadas]

    return pares_encontrados, nao_pareados_a, nao_pareados_b

def processar_comparacao_cenario_pasta_chave(dir_a: str, dir_b: str, limite_linhas: int):
    """
    Orquestrador para o CEN√ÅRIO PASTA-CHAVE.
    """
    pares, nao_pareados_a, nao_pareados_b = encontrar_pares_de_arquivos_por_chave_de_pasta(dir_a, dir_b)
    _executar_e_resumir_comparacoes(pares, nao_pareados_a, nao_pareados_b, limite_linhas)

# --- FUN√á√ÉO COMUM DE EXECU√á√ÉO E RESUMO ---

def _executar_e_resumir_comparacoes(pares: List, nao_pareados_a: List, nao_pareados_b: List, limite_linhas: int):
    """
    Fun√ß√£o gen√©rica que executa a compara√ß√£o avan√ßada e imprime o resumo final.
    """
    print("\n\n######################################################")
    print("###     INICIANDO COMPARA√á√ïES DETALHADAS     ###")
    print("######################################################")
    
    resultados_finais = {}
    if not pares:
        print("\nNenhum par de arquivos foi encontrado para compara√ß√£o detalhada.")
    else:
        for caminho1, caminho2 in pares:
            similaridade = comparador_avancado_arquivos(caminho1, caminho2, limite_linhas_conteudo=limite_linhas)
            # Ajuste no nome do par para cen√°rios mistos
            nome_arq1 = f"{os.path.basename(caminho1)} (de '{os.path.basename(os.path.dirname(caminho1))}')" if "cenario2" in caminho1 else os.path.basename(caminho1)
            resultados_finais[f"{nome_arq1} vs {os.path.basename(caminho2)}"] = similaridade
            print("\n\n")

    print("\n\n######################################################")
    print("###              RESUMO DA EXECU√á√ÉO              ###")
    print("######################################################\n")
    
    print("--- Resultados das Compara√ß√µes ---")
    if resultados_finais:
        for par, score in resultados_finais.items():
            print(f"- {par}: {score:.2%}")
    else:
        print("Nenhuma compara√ß√£o foi executada.")
        
    print("\n--- Itens Sem Par no Diret√≥rio A ---")
    if nao_pareados_a:
        for item in nao_pareados_a:
            print(f"- {os.path.basename(item)}")
    else:
        print("Todos os itens do Diret√≥rio A foram pareados.")

    print("\n--- Arquivos Sem Par no Diret√≥rio B ---")
    if nao_pareados_b:
        for arq in nao_pareados_b:
            print(f"- {os.path.basename(arq)}")
    else:
        print("Todos os arquivos do Diret√≥rio B foram pareados.")
        
    print("\n\n######################################################")
    print("###           EXECU√á√ÉO FINALIZADA                ###")
    print("######################################################")


# ==============================================================================
# BLOCO DE EXECU√á√ÉO E EXEMPLO
# ==============================================================================
if __name__ == '__main__':
    # --- CONTROLES GLOBAIS ---
    
    # 1. ESCOLHA O CEN√ÅRIO DE EXECU√á√ÉO
    USAR_CENARIO_PASTA_COMO_CHAVE = False

    # 2. CONTROLE DE PERFORMANCE
    LIMITE_DE_LINHAS_PARA_ANALISE = 10000

    # Configura√ß√£o do Logger
    nome_log = f"log_comparacao_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.txt"
    sys.stdout = Logger(nome_log)

    print("######################################################")
    print("### IN√çCIO DA EXECU√á√ÉO DO COMPARADOR DE DIRET√ìRIOS ###")
    print("######################################################\n")
    print(f"Log sendo salvo em: {nome_log}\n")
    if LIMITE_DE_LINHAS_PARA_ANALISE:
        print(f"PAR√ÇMETRO DE PERFORMANCE: An√°lise de conte√∫do limitada a {LIMITE_DE_LINHAS_PARA_ANALISE} linhas.\n")
    else:
        print("PAR√ÇMETRO DE PERFORMANCE: An√°lise de conte√∫do far√° a leitura de TODAS as linhas.\n")


    if USAR_CENARIO_PASTA_COMO_CHAVE:
        print("MODO DE EXECU√á√ÉO: Cen√°rio PASTA-COMO-CHAVE selecionado.")
        dir_a = "dir_a_cenario2"
        dir_b = "dir_b_cenario2"
        os.makedirs(dir_a, exist_ok=True)
        os.makedirs(dir_b, exist_ok=True)
        os.makedirs(os.path.join(dir_a, "T_account"), exist_ok=True)
        os.makedirs(os.path.join(dir_a, "T_product"), exist_ok=True)
        os.makedirs(os.path.join(dir_a, "T_sales_unmatched"), exist_ok=True)
        df_account = pd.DataFrame({'id': [1, 2], 'account_name': ['Company A', 'Company B'], 'creation_date': ['2025-01-10', '2025-02-15']})
        df_product = pd.DataFrame({'sku': ['X1', 'Y2'], 'price': [100, 200]})
        df_sales = pd.DataFrame({'date': ['2025-01-01'], 'value': [500]})
        df_supplier = pd.DataFrame({'cnpj': ['11.222.333/0001-44']})
        
        df_account_b = pd.DataFrame({'id': [1, 2], 'account_name': ['Company A', 'Company B'], 'creation_date': ['10/01/2025', '15/02/2025']})

        df_account.to_csv(os.path.join(dir_a, "T_account", "gdfsdf-random-name.csv"), index=False)
        df_product.to_excel(os.path.join(dir_a, "T_product", "data.xlsx"), index=False)
        df_sales.to_csv(os.path.join(dir_a, "T_sales_unmatched", "report.csv"), index=False)
        df_account_b.to_csv(os.path.join(dir_b, "T_account.csv"), index=False)
        df_product.to_excel(os.path.join(dir_b, "T_product.xlsx"), index=False)
        df_supplier.to_csv(os.path.join(dir_b, "T_supplier_unmatched.csv"), index=False)
        
        print(f"Diret√≥rio A: {dir_a}")
        print(f"Diret√≥rio B: {dir_b}")
        print("Ambiente de teste configurado.\n")
        processar_comparacao_cenario_pasta_chave(dir_a, dir_b, limite_linhas=LIMITE_DE_LINHAS_PARA_ANALISE)

    else:
        print("MODO DE EXECU√á√ÉO: Cen√°rio PADR√ÉO (similaridade de estrutura) selecionado.")
        dir_a = "diretorio_A_cenario1"
        dir_b = "diretorio_B_cenario1"
        os.makedirs(dir_a, exist_ok=True)
        os.makedirs(dir_b, exist_ok=True)

        df_clientes_orig = pd.DataFrame({'ID_Cliente': [101, 102], 'Nome': ['Alice', 'Bruno'], 'data_cadastro': ['10-05-2024', '12-06-2024']})
        df_clientes_novo = pd.DataFrame({'ID_Cliente': [101, 102], 'Nome': ['Alice', 'Bruno'], 'data_cadastro': ['2024-05-10', '2024-06-12']})
        df_produtos = pd.DataFrame({'SKU': ['A-001', 'B-002', 'C-003'], 'Produto': ['Notebook', 'Mouse', 'Teclado'], 'Preco': [4500.00, 150.50, 299.90]})
        df_vendas_a = pd.DataFrame({'Data': ['2025-01-10'], 'Valor': [1000]})
        df_fornecedores_b = pd.DataFrame({'CNPJ': ['123456/0001-00'], 'Empresa': ['Fornecedor X']})

        df_clientes_orig.to_csv(os.path.join(dir_a, "base_clientes_jan.csv"), index=False)
        df_produtos.to_excel(os.path.join(dir_a, "catalogo_produtos.xlsx"), index=False)
        df_vendas_a.to_csv(os.path.join(dir_a, "relatorio_vendas.csv"), index=False)
        df_clientes_novo.to_csv(os.path.join(dir_b, "customer_data_01.csv"), index=False)
        df_produtos.to_excel(os.path.join(dir_b, "product_catalog_v2.xlsx"), index=False)
        df_fornecedores_b.to_csv(os.path.join(dir_b, "dados_fornecedores.csv"), index=False)
        
        print(f"Diret√≥rio A: {dir_a}")
        print(f"Diret√≥rio B: {dir_b}")
        print("Ambiente de teste configurado.\n")

        processar_comparacao_cenario_padrao(dir_a, dir_b, limite_linhas=LIMITE_DE_LINHAS_PARA_ANALISE)
